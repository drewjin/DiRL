experiment:
    project: "sdar_eval" # need to be same of this file name
    num_node: 1 # the number of machines you have
    node_index: 0 # no need to change
    function: "eval" # "train" or "eval"

model: "public/SDAR-8B-Chat"
model_base: "sdar"

# dataset you want to eval on, you need to download first, you can also modify your own dataset, see instructions in ./data
dataset:
    eval_dataset: "MATH500" #"MBPP""MATH500""GSM8K""AIME2024""GPQA""LiveCodeBench""HumanEval""LiveBench"
    data_type: "math" #"code""math"

rollout:
    num_response_per_task: 3
    temperature: 1.0
    max_token: 8192 # max generation token num
    block_size: 4
    denoising_steps_per_block: 4
    top_p: 1.0
    top_k: 50
    remasking_strategy: "low_confidence_dynamic" # "low_confidence_dynamic"
    dynamic_threshold: 0.9
    start_with_think: False
    stop_token_list: ["<|im_end|>", "<|endoftext|>"]
    do_sample: True

